{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from preprocessing import TextCleaner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import eli5\n",
    "import json\n",
    "import joblib\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import random\n",
    "# Handle doc/docx/pdf/rtf\n",
    "import textract\n",
    "import docx2txt\n",
    "import fitz\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from striprtf.striprtf import rtf_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def read_file(filename: str):\n",
    "    if filename.endswith(\"docx\"):\n",
    "        text = docx2txt.process(filename)\n",
    "    elif filename.endswith(\"pdf\"):\n",
    "        doc = fitz.open(filename)\n",
    "        text = []\n",
    "        for page in doc:\n",
    "            text.append(page.get_text())\n",
    "        text = \" \".join(text)\n",
    "    elif filename.endswith(\"doc\"):\n",
    "        text = reinterpret(textract.process(filename))\n",
    "        text = remove_convert_info(text)\n",
    "    elif filename.endswith(\"rtf\"):\n",
    "        with open(filename) as f:\n",
    "            content = f.read()\n",
    "            text = rtf_to_text(content)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Does not support the current file extension, currently supported files: 'docx', 'doc' and 'pdf'\"\n",
    "        )\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_json(filename: str):\n",
    "    with open(filename, \"r\") as f:\n",
    "        classes = json.load(f)\n",
    "    return classes\n",
    "\n",
    "\n",
    "def reinterpret(text: str):\n",
    "    return text.decode('utf8')\n",
    "\n",
    "\n",
    "def remove_convert_info(text: str):\n",
    "    for i, s in enumerate(text):\n",
    "        if s == \":\":\n",
    "            break\n",
    "    return text[i + 6:]\n",
    "\n",
    "\n",
    "def save_cls2index(filename: str = \"hacka-aka-embedika/cls2index.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(cls2index, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def metrics(true, preds):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    p = precision_score(true, preds, average='micro')\n",
    "    f1 = f1_score(true, preds, average='micro')\n",
    "    recall = recall_score(true, preds, average='micro')\n",
    "    return {\n",
    "        \"accuracy_score\": acc,\n",
    "        \"precision_score\": p,\n",
    "        \"f1_score\": f1,\n",
    "        \"recall_score\": recall,\n",
    "    }\n",
    "\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "seed_all(42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "json_file = \"hacka-aka-embedika/classes.json\"\n",
    "dataset_path = \"hacka-aka-embedika/docs\"\n",
    "classes = read_json(json_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5908cb5da047d6c9e6dfea6337fb3189.doc\n",
      "14711e4fc8e56f0c75856c8837ec04cb.doc\n",
      "7eb67b5aecf3f3190aab0a5f8ea32172.docx\n",
      "b40a9d048b199d5f4db62a6a2335f2a0.pdf\n",
      "84fec112d02288861e7af59f468131fb.docx\n",
      "f6377999f8a5aa9a09b03e428ac93153.doc\n",
      "a525f050cef10dee3a42468daec064ff.doc\n",
      "bec0aa38d1383172690a18d16b07f154.doc\n",
      "214d620d9c54bc83111277dd872d3cb2.pdf\n",
      "d143c89d002fcef3e2bd2efdb4966f55.doc\n",
      "2fd747f38e30ae7ce1c9d6e3b907ac5d.doc\n",
      "4c2c295e81f4a6c3e669e8f76c6ce423.docx\n",
      "64f58bc6e1207a570a38d771609b2cf1.docx\n",
      "7ecd641f2ad81961c17455ed3ebeb2ab.doc\n",
      "4e583dc5a5f1499fd2408f3152589f2d.doc\n",
      "79104075f8b2ff971d51c495e67af52c.pdf\n",
      "19e2becdb0f10e1c16a5a2460f3a84a2.pdf\n",
      "0f7f507d0af90aba3c35484de016d8b4.doc\n",
      "69ab7557dee21939aa7432b23a54cb2b.doc\n",
      "8b82f3c800e486d9da9a13c98f7a40d6.doc\n",
      "856860329f573bbaf158e1eafa885ba5.docx\n",
      "35b6a0f57d909507c5aa9a8972b15f35.pdf\n",
      "f28d4a853be12515dae73a5912bc5b41.doc\n",
      "2c758805e2917306e6cbb079e2adcfcf.rtf\n",
      "4db6b233fda895c3bffcb5fdc5b8e1de.rtf\n",
      "18d573815c15b4e798bdfbfb52fb2f43.docx\n",
      "d54c0b06162cf7cf57e8b1e7356aa204.doc\n",
      "a69f5a60f3fd9a081cb0528dd461be45.doc\n",
      "41b36e9a90f36be9ed2a2b4f44e5c848.doc\n",
      "b19a67817142ea9f2231aa63dfd2981c.docx\n",
      "317e4552102e82bd9e17ba1205cd4367.docx\n",
      "67170dee29deff9bc80087a94aef7ea4.doc\n",
      "cbf3217807791a37499a7b8d94616fdc.doc\n",
      "259b481366842141111305897cce7486.docx\n",
      "6df1c02e4f9adaa9b87126dc3cb2d72b.doc\n",
      "eddc39f5f675890f285014c886bf22c9.doc\n",
      "2351cf256df1b683a425211c1ed0e848.doc\n",
      "85a65ecc4763c760f914382d6e26b1f1.doc\n",
      "e3f3df754bdf7578a71b7a9fa1500ad9.rtf\n",
      "0b4be82b86eff410d69d1d6b5553d220.docx\n",
      "736cc87395089b9611b0db70d2999d75.pdf\n",
      "7ce2d613ac62ec5e4ef3d988c1f91582.doc\n",
      "2060962a8b7ca4c45dc041c3f624225a.doc\n",
      "b95bbf14eb26ac912b1339e321cbca34.doc\n",
      "910ccf7c9b029846e4390ddac5f8d687.doc\n",
      "82b672721c50b8897a3cf7c98c0d8e0c.rtf\n",
      "81a64023bdb74032827385d43181ea3a.pdf\n",
      "6cd62be718ceb49408c49e00e7b12a5e.doc\n",
      "f8eabec67b770c384d84f9feb7e02543.doc\n",
      "f96c2a58215aa54aeb6713cbb457fad9.doc\n",
      "02682d726b725f95b9ee85f751c043d0.doc\n",
      "62e280b12c607701866006e37ad990a5.doc\n",
      "d0e8ce466209873b70ddfdbacf0eef71.doc\n",
      "6b18c046e7ccfdaf9123c11980f56c35.doc\n",
      "641282d3072e91ab05c97110e0340020.docx\n",
      "49bce5af1c98cd017a310ea8edd3e55b.doc\n",
      "7a120d4c7cec157324effa671e2d0812.docx\n",
      "7aff676ead9fe323b2c542e60accb1ae.doc\n",
      "b7acf29be1d3e4b9cb529683e676fadb.doc\n",
      "6babd660f1a9192017a06b7e93bea919.doc\n",
      "453b2cb6e4ba7b8d1a8382773880d313.doc\n",
      "2b408919fd9833dc3f6892aad753f21f.docx\n",
      "8540a7dccb3a9e4d0a1a2611e077ce9d.doc\n",
      "66ee9b692a6b9c690564c92121a76b15.doc\n",
      "508bdc1406af695fd7ab1f22b69b9857.doc\n",
      "981d5a0ebbecffa588848251d0750fec.doc\n",
      "3031ff9bc88ad88532311b419267c875.doc\n",
      "e6a90919eab84ecbbdca11016c37b3a9.doc\n",
      "a0e06a957c1a729fe1d978605680e2ae.doc\n",
      "a7966d0674c94a6e752e3a5832edb2a9.doc\n",
      "8ee681886de97951748528c7c78d03a7.docx\n",
      "b303afea664ed05cdbc73a8c3b31b09d.docx\n",
      "03a70fe60be9ecc2a63798a361fc9689.docx\n",
      "c3141b7956167ce3987b82beb6cf73c4.doc\n",
      "a40a0347f0a91f2537ccc67c46d883b7.doc\n",
      "2b25ecf601a9ce0c2a33c8e1d9746df2.doc\n",
      "ef140e96384a29057445d0a889f1ad50.doc\n",
      "bdfb262c00991dddebfc5d4a87604284.doc\n",
      "3588ff6fb8f5c5a5f70196500198ca3a.doc\n",
      "123c9dd7b2736589f1f286d2112bc4eb.doc\n",
      "cf89a65d4477656ec05262ae55bb6aaa.doc\n",
      "616d4446e85de23f29337a6e089c67cb.doc\n",
      "2d4708c800dc003466fa9a8a64e2e2b7.docx\n",
      "82e5f04228e8d6768de9e4a4c565e89f.doc\n",
      "317dc2690741c169db9dc901ff5a3258.docx\n",
      "5e9754740f6c89a96cf5996404ec3c27.doc\n",
      "855c8450351c98a25ea2ac22a0256c7f.doc\n",
      "a8a9861b63d26f13f0f10a075158b6da.doc\n",
      "58c8976ca35aa805aa9d21246d5d18ee.doc\n",
      "7e0cf1019baa9e1cdabcfc06d522d424.doc\n",
      "242b138fd2025b7a5207876098355e03.docx\n",
      "e6a6d61368866475f346f078cf2cbe60.doc\n",
      "dda3ea2dc3a078682620f926a54aa0bf.doc\n",
      "97d4cf03b88c9e040557ab1b61e2e7a2.doc\n",
      "f3734851311f2a7ac6c66ad7ccbe1d2c.doc\n",
      "99a11e3e403b7c8b0773108a84839517.doc\n",
      "084edc7dfc3db04e3a3c55c102f47bcb.doc\n",
      "15e3d16cf68646b3383d386aae2a6849.doc\n",
      "073a0d372820c3c2bffe9ba24a7ed7af.doc\n",
      "2054a58154349bc54b691666fe3f89b1.pdf\n",
      "5262e9c377c3ab1f6b8141762cca69ad.doc\n",
      "4a5707e447271a188a1211606b158a94.pdf\n",
      "91ba127aad1b88905603ecc3aacac0d1.doc\n",
      "abcec818adbe358f8071a75e0fe2cc49.pdf\n",
      "137eaaa047f557233943012897e46cec.doc\n",
      "31d24c0d4694e7c2fb19933b84414b40.doc\n",
      "8c5ce9a193c788cadf94ddec5607f3b4.docx\n",
      "86d6d0062e91651ccc3d3ce35b162bf8.doc\n",
      "086ad48895d2a73854b6151decc28800.pdf\n",
      "bd9b731375abcdb9969af05ec9fb03fa.doc\n",
      "a543a2a59bd604ad1224040b14844b49.docx\n",
      "34f5456e56beb78b311728f738167d3a.doc\n",
      "ff6882cb4a3ec31dec18a94e1d1745b1.doc\n",
      "c7a0230f5a8e1cbe7a6bec435b71a43c.docx\n",
      "f57fe87f15a6dee2b17e804421be63b5.pdf\n",
      "1ea8809d696a4bd6a2076fbc6fd28c23.doc\n",
      "57962abd8dbe0ce0c7056896ee4501f1.doc\n",
      "2c81df29db63aebf495106881a52188f.doc\n",
      "0ca2f9faecdbc67d6686a9f5b6636eba.doc\n"
     ]
    }
   ],
   "source": [
    "data = {\"filename\": [], \"text\": [], \"class\": []}\n",
    "cls2index = {}\n",
    "for filename, cls in classes.items():\n",
    "    print(filename)\n",
    "    data[\"filename\"].append(filename)\n",
    "    text = read_file(os.path.join(dataset_path, filename))\n",
    "    data[\"text\"].append(text)\n",
    "    cls = cls.strip()\n",
    "    data[\"class\"].append(cls)\n",
    "    if cls not in cls2index:\n",
    "        cls2index[cls] = len(cls2index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "                                  filename  \\\n0     5908cb5da047d6c9e6dfea6337fb3189.doc   \n1     14711e4fc8e56f0c75856c8837ec04cb.doc   \n2    7eb67b5aecf3f3190aab0a5f8ea32172.docx   \n3     b40a9d048b199d5f4db62a6a2335f2a0.pdf   \n4    84fec112d02288861e7af59f468131fb.docx   \n..                                     ...   \n114   f57fe87f15a6dee2b17e804421be63b5.pdf   \n115   1ea8809d696a4bd6a2076fbc6fd28c23.doc   \n116   57962abd8dbe0ce0c7056896ee4501f1.doc   \n117   2c81df29db63aebf495106881a52188f.doc   \n118   0ca2f9faecdbc67d6686a9f5b6636eba.doc   \n\n                                                  text  \\\n0    \\n﻿\\t\\tДОГОВОР \\n\\nг. Москва\\n«__» ________ 20...   \n1    \\n﻿\\n\\nДоговор №______________\\n\\n\\n Дата, мес...   \n2    ДОГОВОР ЗАКУПКИ № __________/\\n\\n\\n\\nг.\\t\\t\\t\\...   \n3     \\n \\n \\nДОГОВОР ПОСТАВКИ № 1 \\nг. Москва \\n  ...   \n4    Договор  № {НомерДокумента}\\n\\n\\n\\n{ДатаДокуме...   \n..                                                 ...   \n114  Страница 1 из 8 \\n \\n \\nДОГОВОР КУПЛИ-ПРОДАЖИ ...   \n115  \\n﻿ДОГОВОР\\n\\nг. Москва\\n«_____» _____________...   \n116  \\n﻿ПРЕДВАРИТЕЛЬНЫЙ ДОГОВОР\\n\\nг. Москва\\n«____...   \n117  \\n﻿ДОГОВОР\\n№ __\\n\\nг.________________\\t\\t\\t\\t...   \n118  \\n﻿\\nДОГОВОР № _____\\n\\nг. Омск\\t\\t\\t\\t\\t\\t   ...   \n\n                      class  cls  \n0         Договоры поставки    0  \n1         Договоры поставки    0  \n2         Договоры поставки    0  \n3         Договоры поставки    0  \n4         Договоры поставки    0  \n..                      ...  ...  \n114  Договоры купли-продажи    4  \n115  Договоры купли-продажи    4  \n116  Договоры купли-продажи    4  \n117  Договоры купли-продажи    4  \n118  Договоры купли-продажи    4  \n\n[119 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>text</th>\n      <th>class</th>\n      <th>cls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5908cb5da047d6c9e6dfea6337fb3189.doc</td>\n      <td>\\n﻿\\t\\tДОГОВОР \\n\\nг. Москва\\n«__» ________ 20...</td>\n      <td>Договоры поставки</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14711e4fc8e56f0c75856c8837ec04cb.doc</td>\n      <td>\\n﻿\\n\\nДоговор №______________\\n\\n\\n Дата, мес...</td>\n      <td>Договоры поставки</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7eb67b5aecf3f3190aab0a5f8ea32172.docx</td>\n      <td>ДОГОВОР ЗАКУПКИ № __________/\\n\\n\\n\\nг.\\t\\t\\t\\...</td>\n      <td>Договоры поставки</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b40a9d048b199d5f4db62a6a2335f2a0.pdf</td>\n      <td>\\n \\n \\nДОГОВОР ПОСТАВКИ № 1 \\nг. Москва \\n  ...</td>\n      <td>Договоры поставки</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84fec112d02288861e7af59f468131fb.docx</td>\n      <td>Договор  № {НомерДокумента}\\n\\n\\n\\n{ДатаДокуме...</td>\n      <td>Договоры поставки</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>f57fe87f15a6dee2b17e804421be63b5.pdf</td>\n      <td>Страница 1 из 8 \\n \\n \\nДОГОВОР КУПЛИ-ПРОДАЖИ ...</td>\n      <td>Договоры купли-продажи</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>1ea8809d696a4bd6a2076fbc6fd28c23.doc</td>\n      <td>\\n﻿ДОГОВОР\\n\\nг. Москва\\n«_____» _____________...</td>\n      <td>Договоры купли-продажи</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>57962abd8dbe0ce0c7056896ee4501f1.doc</td>\n      <td>\\n﻿ПРЕДВАРИТЕЛЬНЫЙ ДОГОВОР\\n\\nг. Москва\\n«____...</td>\n      <td>Договоры купли-продажи</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>2c81df29db63aebf495106881a52188f.doc</td>\n      <td>\\n﻿ДОГОВОР\\n№ __\\n\\nг.________________\\t\\t\\t\\t...</td>\n      <td>Договоры купли-продажи</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>0ca2f9faecdbc67d6686a9f5b6636eba.doc</td>\n      <td>\\n﻿\\nДОГОВОР № _____\\n\\nг. Омск\\t\\t\\t\\t\\t\\t   ...</td>\n      <td>Договоры купли-продажи</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>119 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "df[\"cls\"] = df[\"class\"].apply(lambda row: cls2index[row])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "{'0': 'Договоры поставки',\n '1': 'Договоры оказания услуг',\n '2': 'Договоры подряда',\n '3': 'Договоры аренды',\n '4': 'Договоры купли-продажи'}"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = read_json(\"index2cls.json\")\n",
    "cls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/xrenya/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-sentence/snapshots/78b5122d6365337dd4114281b0d08cd1edbb3bc8/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/xrenya/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-sentence/snapshots/78b5122d6365337dd4114281b0d08cd1edbb3bc8/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/xrenya/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-sentence/snapshots/78b5122d6365337dd4114281b0d08cd1edbb3bc8/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/xrenya/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-sentence/snapshots/78b5122d6365337dd4114281b0d08cd1edbb3bc8/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"DeepPavlov/rubert-base-cased-sentence\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/xrenya/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-sentence/snapshots/78b5122d6365337dd4114281b0d08cd1edbb3bc8/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/xrenya/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-sentence/snapshots/78b5122d6365337dd4114281b0d08cd1edbb3bc8/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-sentence and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\", num_labels=len(cls)).to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"].values.tolist(), df[\"cls\"].values.tolist(), test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Cleaning and parsing the text.\n",
    "\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    nopunc = clean_text(text)\n",
    "    tokenized_text = tokenizer.tokenize(nopunc)\n",
    "    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n",
    "    combined_text = ' '.join(tokenized_text)\n",
    "    return combined_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "X_train_clean = []\n",
    "X_test_clean = []\n",
    "\n",
    "for s in X_train:\n",
    "    X_train_clean.append(text_preprocessing(s))\n",
    "\n",
    "for s in X_test:\n",
    "    X_test_clean.append(text_preprocessing(s))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokens_train_ = tokenizer.batch_encode_plus(\n",
    "    X_train_clean,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    X_train_clean,\n",
    "    max_length=512,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    X_test_clean,\n",
    "    max_length=512,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Data(tokens_train, y_train)\n",
    "test_dataset = Data(tokens_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    return {'F1': f1}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', #Выходной каталог\n",
    "    num_train_epochs=150, #Кол-во эпох для обучения\n",
    "    per_device_train_batch_size=96, #Размер пакета для каждого устройства во время обучения\n",
    "    per_device_eval_batch_size=96, #Размер пакета для каждого устройства во время валидации\n",
    "    weight_decay=0.00001, #Понижение весов\n",
    "    logging_dir='./logs', #Каталог для хранения журналов\n",
    "    load_best_model_at_end=True, #Загружать ли лучшую модель после обучения\n",
    "    learning_rate=0.002, #Скорость обучения\n",
    "    evaluation_strategy='epoch', #Валидация после каждой эпохи (можно сделать после конкретного кол-ва шагов)\n",
    "    logging_strategy='epoch', #Логирование после каждой эпохи\n",
    "    save_strategy='epoch', #Сохранение после каждой эпохи\n",
    "    save_total_limit=1,\n",
    "    seed=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  tokenizer=tokenizer,\n",
    "                  args=training_args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=train_dataset,\n",
    "                  compute_metrics=compute_metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xrenya/miniconda3/envs/doc/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 95\n",
      "  Num Epochs = 150\n",
      "  Instantaneous batch size per device = 96\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 96\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 3845\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/150 : < :, Epoch 1/150]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-1\n",
      "Configuration saved in ./results/checkpoint-1/config.json\n",
      "Model weights saved in ./results/checkpoint-1/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-2\n",
      "Configuration saved in ./results/checkpoint-2/config.json\n",
      "Model weights saved in ./results/checkpoint-2/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-3\n",
      "Configuration saved in ./results/checkpoint-3/config.json\n",
      "Model weights saved in ./results/checkpoint-3/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-4\n",
      "Configuration saved in ./results/checkpoint-4/config.json\n",
      "Model weights saved in ./results/checkpoint-4/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-4/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-5\n",
      "Configuration saved in ./results/checkpoint-5/config.json\n",
      "Model weights saved in ./results/checkpoint-5/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-5/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-3] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-6\n",
      "Configuration saved in ./results/checkpoint-6/config.json\n",
      "Model weights saved in ./results/checkpoint-6/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-6/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-4] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-7\n",
      "Configuration saved in ./results/checkpoint-7/config.json\n",
      "Model weights saved in ./results/checkpoint-7/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-7/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-5] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-8\n",
      "Configuration saved in ./results/checkpoint-8/config.json\n",
      "Model weights saved in ./results/checkpoint-8/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-8/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-9\n",
      "Configuration saved in ./results/checkpoint-9/config.json\n",
      "Model weights saved in ./results/checkpoint-9/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-9/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-7] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-10\n",
      "Configuration saved in ./results/checkpoint-10/config.json\n",
      "Model weights saved in ./results/checkpoint-10/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-10/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-8] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-11\n",
      "Configuration saved in ./results/checkpoint-11/config.json\n",
      "Model weights saved in ./results/checkpoint-11/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-11/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-11/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-9] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-12\n",
      "Configuration saved in ./results/checkpoint-12/config.json\n",
      "Model weights saved in ./results/checkpoint-12/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-12/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-12/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-10] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-13\n",
      "Configuration saved in ./results/checkpoint-13/config.json\n",
      "Model weights saved in ./results/checkpoint-13/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-13/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-13/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-11] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-14\n",
      "Configuration saved in ./results/checkpoint-14/config.json\n",
      "Model weights saved in ./results/checkpoint-14/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-14/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-14/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-12] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-15\n",
      "Configuration saved in ./results/checkpoint-15/config.json\n",
      "Model weights saved in ./results/checkpoint-15/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-15/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-15/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-13] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-16\n",
      "Configuration saved in ./results/checkpoint-16/config.json\n",
      "Model weights saved in ./results/checkpoint-16/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-16/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-16/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-14] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-17\n",
      "Configuration saved in ./results/checkpoint-17/config.json\n",
      "Model weights saved in ./results/checkpoint-17/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-17/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-17/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-15] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-18\n",
      "Configuration saved in ./results/checkpoint-18/config.json\n",
      "Model weights saved in ./results/checkpoint-18/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-18/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-18/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-16] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-19\n",
      "Configuration saved in ./results/checkpoint-19/config.json\n",
      "Model weights saved in ./results/checkpoint-19/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-19/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-19/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-17] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-20\n",
      "Configuration saved in ./results/checkpoint-20/config.json\n",
      "Model weights saved in ./results/checkpoint-20/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-20/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-20/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-18] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-21\n",
      "Configuration saved in ./results/checkpoint-21/config.json\n",
      "Model weights saved in ./results/checkpoint-21/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-21/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-21/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-19] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-22\n",
      "Configuration saved in ./results/checkpoint-22/config.json\n",
      "Model weights saved in ./results/checkpoint-22/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-22/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-22/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-20] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-23\n",
      "Configuration saved in ./results/checkpoint-23/config.json\n",
      "Model weights saved in ./results/checkpoint-23/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-23/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-23/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-21] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-24\n",
      "Configuration saved in ./results/checkpoint-24/config.json\n",
      "Model weights saved in ./results/checkpoint-24/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-24/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-24/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-22] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-25\n",
      "Configuration saved in ./results/checkpoint-25/config.json\n",
      "Model weights saved in ./results/checkpoint-25/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-25/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-25/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-23] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-26\n",
      "Configuration saved in ./results/checkpoint-26/config.json\n",
      "Model weights saved in ./results/checkpoint-26/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-26/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-26/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-24] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-27\n",
      "Configuration saved in ./results/checkpoint-27/config.json\n",
      "Model weights saved in ./results/checkpoint-27/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-27/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-27/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-25] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-28\n",
      "Configuration saved in ./results/checkpoint-28/config.json\n",
      "Model weights saved in ./results/checkpoint-28/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-28/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-28/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-26] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-29\n",
      "Configuration saved in ./results/checkpoint-29/config.json\n",
      "Model weights saved in ./results/checkpoint-29/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-29/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-29/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-27] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-30\n",
      "Configuration saved in ./results/checkpoint-30/config.json\n",
      "Model weights saved in ./results/checkpoint-30/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-30/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-30/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-28] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-31\n",
      "Configuration saved in ./results/checkpoint-31/config.json\n",
      "Model weights saved in ./results/checkpoint-31/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-31/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-31/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-29] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-32\n",
      "Configuration saved in ./results/checkpoint-32/config.json\n",
      "Model weights saved in ./results/checkpoint-32/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-32/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-32/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-30] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-33\n",
      "Configuration saved in ./results/checkpoint-33/config.json\n",
      "Model weights saved in ./results/checkpoint-33/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-33/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-33/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-31] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-34\n",
      "Configuration saved in ./results/checkpoint-34/config.json\n",
      "Model weights saved in ./results/checkpoint-34/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-34/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-34/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-35\n",
      "Configuration saved in ./results/checkpoint-35/config.json\n",
      "Model weights saved in ./results/checkpoint-35/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-35/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-35/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-33] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-36\n",
      "Configuration saved in ./results/checkpoint-36/config.json\n",
      "Model weights saved in ./results/checkpoint-36/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-36/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-36/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-34] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-37\n",
      "Configuration saved in ./results/checkpoint-37/config.json\n",
      "Model weights saved in ./results/checkpoint-37/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-37/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-37/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-35] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-38\n",
      "Configuration saved in ./results/checkpoint-38/config.json\n",
      "Model weights saved in ./results/checkpoint-38/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-38/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-38/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-36] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-39\n",
      "Configuration saved in ./results/checkpoint-39/config.json\n",
      "Model weights saved in ./results/checkpoint-39/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-39/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-39/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-37] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-40\n",
      "Configuration saved in ./results/checkpoint-40/config.json\n",
      "Model weights saved in ./results/checkpoint-40/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-40/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-40/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-38] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-41\n",
      "Configuration saved in ./results/checkpoint-41/config.json\n",
      "Model weights saved in ./results/checkpoint-41/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-41/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-41/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-39] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-42\n",
      "Configuration saved in ./results/checkpoint-42/config.json\n",
      "Model weights saved in ./results/checkpoint-42/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-42/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-42/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-40] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-43\n",
      "Configuration saved in ./results/checkpoint-43/config.json\n",
      "Model weights saved in ./results/checkpoint-43/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-43/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-43/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-41] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-44\n",
      "Configuration saved in ./results/checkpoint-44/config.json\n",
      "Model weights saved in ./results/checkpoint-44/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-44/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-44/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-42] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-45\n",
      "Configuration saved in ./results/checkpoint-45/config.json\n",
      "Model weights saved in ./results/checkpoint-45/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-45/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-45/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-43] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-46\n",
      "Configuration saved in ./results/checkpoint-46/config.json\n",
      "Model weights saved in ./results/checkpoint-46/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-46/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-46/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-44] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-47\n",
      "Configuration saved in ./results/checkpoint-47/config.json\n",
      "Model weights saved in ./results/checkpoint-47/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-47/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-47/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-45] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-48\n",
      "Configuration saved in ./results/checkpoint-48/config.json\n",
      "Model weights saved in ./results/checkpoint-48/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-48/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-48/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-46] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-49\n",
      "Configuration saved in ./results/checkpoint-49/config.json\n",
      "Model weights saved in ./results/checkpoint-49/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-49/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-49/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-47] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-50/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-48] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-51\n",
      "Configuration saved in ./results/checkpoint-51/config.json\n",
      "Model weights saved in ./results/checkpoint-51/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-51/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-51/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-49] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-52\n",
      "Configuration saved in ./results/checkpoint-52/config.json\n",
      "Model weights saved in ./results/checkpoint-52/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-52/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-52/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-50] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-53\n",
      "Configuration saved in ./results/checkpoint-53/config.json\n",
      "Model weights saved in ./results/checkpoint-53/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-53/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-53/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-54\n",
      "Configuration saved in ./results/checkpoint-54/config.json\n",
      "Model weights saved in ./results/checkpoint-54/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-54/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-54/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-52] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-55\n",
      "Configuration saved in ./results/checkpoint-55/config.json\n",
      "Model weights saved in ./results/checkpoint-55/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-55/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-55/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-53] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-56\n",
      "Configuration saved in ./results/checkpoint-56/config.json\n",
      "Model weights saved in ./results/checkpoint-56/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-56/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-56/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-54] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-57\n",
      "Configuration saved in ./results/checkpoint-57/config.json\n",
      "Model weights saved in ./results/checkpoint-57/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-57/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-57/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-55] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-58\n",
      "Configuration saved in ./results/checkpoint-58/config.json\n",
      "Model weights saved in ./results/checkpoint-58/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-58/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-58/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-56] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-59\n",
      "Configuration saved in ./results/checkpoint-59/config.json\n",
      "Model weights saved in ./results/checkpoint-59/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-59/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-59/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-57] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-60\n",
      "Configuration saved in ./results/checkpoint-60/config.json\n",
      "Model weights saved in ./results/checkpoint-60/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-60/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-60/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-58] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-61\n",
      "Configuration saved in ./results/checkpoint-61/config.json\n",
      "Model weights saved in ./results/checkpoint-61/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-61/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-61/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-59] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-62\n",
      "Configuration saved in ./results/checkpoint-62/config.json\n",
      "Model weights saved in ./results/checkpoint-62/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-62/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-62/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-60] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-63\n",
      "Configuration saved in ./results/checkpoint-63/config.json\n",
      "Model weights saved in ./results/checkpoint-63/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-63/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-63/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-61] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-64\n",
      "Configuration saved in ./results/checkpoint-64/config.json\n",
      "Model weights saved in ./results/checkpoint-64/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-64/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-64/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-62] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-65\n",
      "Configuration saved in ./results/checkpoint-65/config.json\n",
      "Model weights saved in ./results/checkpoint-65/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-65/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-65/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-63] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-66\n",
      "Configuration saved in ./results/checkpoint-66/config.json\n",
      "Model weights saved in ./results/checkpoint-66/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-66/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-66/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-67\n",
      "Configuration saved in ./results/checkpoint-67/config.json\n",
      "Model weights saved in ./results/checkpoint-67/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-67/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-67/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-65] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-68\n",
      "Configuration saved in ./results/checkpoint-68/config.json\n",
      "Model weights saved in ./results/checkpoint-68/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-68/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-68/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-66] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-69\n",
      "Configuration saved in ./results/checkpoint-69/config.json\n",
      "Model weights saved in ./results/checkpoint-69/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-69/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-69/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-67] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-70\n",
      "Configuration saved in ./results/checkpoint-70/config.json\n",
      "Model weights saved in ./results/checkpoint-70/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-70/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-70/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-68] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-71\n",
      "Configuration saved in ./results/checkpoint-71/config.json\n",
      "Model weights saved in ./results/checkpoint-71/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-71/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-71/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-69] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-72\n",
      "Configuration saved in ./results/checkpoint-72/config.json\n",
      "Model weights saved in ./results/checkpoint-72/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-72/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-72/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-70] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-73\n",
      "Configuration saved in ./results/checkpoint-73/config.json\n",
      "Model weights saved in ./results/checkpoint-73/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-73/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-73/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-71] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-74\n",
      "Configuration saved in ./results/checkpoint-74/config.json\n",
      "Model weights saved in ./results/checkpoint-74/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-74/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-74/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-72] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-75\n",
      "Configuration saved in ./results/checkpoint-75/config.json\n",
      "Model weights saved in ./results/checkpoint-75/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-75/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-75/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-73] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-76\n",
      "Configuration saved in ./results/checkpoint-76/config.json\n",
      "Model weights saved in ./results/checkpoint-76/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-76/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-76/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-74] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-77\n",
      "Configuration saved in ./results/checkpoint-77/config.json\n",
      "Model weights saved in ./results/checkpoint-77/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-77/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-77/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-75] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-78\n",
      "Configuration saved in ./results/checkpoint-78/config.json\n",
      "Model weights saved in ./results/checkpoint-78/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-78/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-78/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-76] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-79\n",
      "Configuration saved in ./results/checkpoint-79/config.json\n",
      "Model weights saved in ./results/checkpoint-79/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-79/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-79/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-77] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-80\n",
      "Configuration saved in ./results/checkpoint-80/config.json\n",
      "Model weights saved in ./results/checkpoint-80/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-80/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-80/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-78] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-81\n",
      "Configuration saved in ./results/checkpoint-81/config.json\n",
      "Model weights saved in ./results/checkpoint-81/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-81/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-81/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-79] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-82\n",
      "Configuration saved in ./results/checkpoint-82/config.json\n",
      "Model weights saved in ./results/checkpoint-82/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-82/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-82/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-80] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-83\n",
      "Configuration saved in ./results/checkpoint-83/config.json\n",
      "Model weights saved in ./results/checkpoint-83/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-83/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-83/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-81] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-84\n",
      "Configuration saved in ./results/checkpoint-84/config.json\n",
      "Model weights saved in ./results/checkpoint-84/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-84/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-84/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-82] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-85\n",
      "Configuration saved in ./results/checkpoint-85/config.json\n",
      "Model weights saved in ./results/checkpoint-85/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-85/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-85/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-83] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-86\n",
      "Configuration saved in ./results/checkpoint-86/config.json\n",
      "Model weights saved in ./results/checkpoint-86/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-86/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-86/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-84] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-87\n",
      "Configuration saved in ./results/checkpoint-87/config.json\n",
      "Model weights saved in ./results/checkpoint-87/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-87/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-87/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-85] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-88\n",
      "Configuration saved in ./results/checkpoint-88/config.json\n",
      "Model weights saved in ./results/checkpoint-88/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-88/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-86] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-89\n",
      "Configuration saved in ./results/checkpoint-89/config.json\n",
      "Model weights saved in ./results/checkpoint-89/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-89/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-89/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-87] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-90\n",
      "Configuration saved in ./results/checkpoint-90/config.json\n",
      "Model weights saved in ./results/checkpoint-90/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-90/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-90/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-88] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-91\n",
      "Configuration saved in ./results/checkpoint-91/config.json\n",
      "Model weights saved in ./results/checkpoint-91/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-91/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-91/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-89] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-92\n",
      "Configuration saved in ./results/checkpoint-92/config.json\n",
      "Model weights saved in ./results/checkpoint-92/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-92/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-92/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-90] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-93\n",
      "Configuration saved in ./results/checkpoint-93/config.json\n",
      "Model weights saved in ./results/checkpoint-93/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-93/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-93/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-91] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-94\n",
      "Configuration saved in ./results/checkpoint-94/config.json\n",
      "Model weights saved in ./results/checkpoint-94/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-94/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-94/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-92] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-95\n",
      "Configuration saved in ./results/checkpoint-95/config.json\n",
      "Model weights saved in ./results/checkpoint-95/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-95/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-95/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-93] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-96\n",
      "Configuration saved in ./results/checkpoint-96/config.json\n",
      "Model weights saved in ./results/checkpoint-96/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-96/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-96/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-94] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-97\n",
      "Configuration saved in ./results/checkpoint-97/config.json\n",
      "Model weights saved in ./results/checkpoint-97/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-97/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-97/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-95] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-98\n",
      "Configuration saved in ./results/checkpoint-98/config.json\n",
      "Model weights saved in ./results/checkpoint-98/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-98/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-98/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-99\n",
      "Configuration saved in ./results/checkpoint-99/config.json\n",
      "Model weights saved in ./results/checkpoint-99/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-99/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-99/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-97] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-100\n",
      "Configuration saved in ./results/checkpoint-100/config.json\n",
      "Model weights saved in ./results/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-98] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-101\n",
      "Configuration saved in ./results/checkpoint-101/config.json\n",
      "Model weights saved in ./results/checkpoint-101/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-101/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-101/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-99] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-102\n",
      "Configuration saved in ./results/checkpoint-102/config.json\n",
      "Model weights saved in ./results/checkpoint-102/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-102/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-102/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-103\n",
      "Configuration saved in ./results/checkpoint-103/config.json\n",
      "Model weights saved in ./results/checkpoint-103/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-103/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-103/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-101] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-104\n",
      "Configuration saved in ./results/checkpoint-104/config.json\n",
      "Model weights saved in ./results/checkpoint-104/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-104/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-104/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-105\n",
      "Configuration saved in ./results/checkpoint-105/config.json\n",
      "Model weights saved in ./results/checkpoint-105/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-105/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-105/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-103] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-106\n",
      "Configuration saved in ./results/checkpoint-106/config.json\n",
      "Model weights saved in ./results/checkpoint-106/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-106/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-106/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-104] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-107\n",
      "Configuration saved in ./results/checkpoint-107/config.json\n",
      "Model weights saved in ./results/checkpoint-107/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-107/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-107/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-105] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-108\n",
      "Configuration saved in ./results/checkpoint-108/config.json\n",
      "Model weights saved in ./results/checkpoint-108/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-108/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-108/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-106] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-109\n",
      "Configuration saved in ./results/checkpoint-109/config.json\n",
      "Model weights saved in ./results/checkpoint-109/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-109/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-109/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-107] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-110\n",
      "Configuration saved in ./results/checkpoint-110/config.json\n",
      "Model weights saved in ./results/checkpoint-110/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-110/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-110/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-108] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-111\n",
      "Configuration saved in ./results/checkpoint-111/config.json\n",
      "Model weights saved in ./results/checkpoint-111/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-111/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-111/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-109] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-112\n",
      "Configuration saved in ./results/checkpoint-112/config.json\n",
      "Model weights saved in ./results/checkpoint-112/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-112/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-112/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-110] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-113\n",
      "Configuration saved in ./results/checkpoint-113/config.json\n",
      "Model weights saved in ./results/checkpoint-113/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-113/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-113/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-111] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-114\n",
      "Configuration saved in ./results/checkpoint-114/config.json\n",
      "Model weights saved in ./results/checkpoint-114/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-114/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-114/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-112] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-115\n",
      "Configuration saved in ./results/checkpoint-115/config.json\n",
      "Model weights saved in ./results/checkpoint-115/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-115/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-115/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-113] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-116\n",
      "Configuration saved in ./results/checkpoint-116/config.json\n",
      "Model weights saved in ./results/checkpoint-116/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-116/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-116/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-114] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-117\n",
      "Configuration saved in ./results/checkpoint-117/config.json\n",
      "Model weights saved in ./results/checkpoint-117/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-117/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-117/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-115] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-118\n",
      "Configuration saved in ./results/checkpoint-118/config.json\n",
      "Model weights saved in ./results/checkpoint-118/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-118/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-118/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-116] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-119\n",
      "Configuration saved in ./results/checkpoint-119/config.json\n",
      "Model weights saved in ./results/checkpoint-119/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-119/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-119/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-117] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-120\n",
      "Configuration saved in ./results/checkpoint-120/config.json\n",
      "Model weights saved in ./results/checkpoint-120/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-120/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-120/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-118] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-121\n",
      "Configuration saved in ./results/checkpoint-121/config.json\n",
      "Model weights saved in ./results/checkpoint-121/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-121/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-121/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-119] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-122\n",
      "Configuration saved in ./results/checkpoint-122/config.json\n",
      "Model weights saved in ./results/checkpoint-122/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-122/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-122/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-120] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-123\n",
      "Configuration saved in ./results/checkpoint-123/config.json\n",
      "Model weights saved in ./results/checkpoint-123/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-123/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-123/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-121] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-124\n",
      "Configuration saved in ./results/checkpoint-124/config.json\n",
      "Model weights saved in ./results/checkpoint-124/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-124/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-124/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-125\n",
      "Configuration saved in ./results/checkpoint-125/config.json\n",
      "Model weights saved in ./results/checkpoint-125/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-125/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-125/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-123] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-126\n",
      "Configuration saved in ./results/checkpoint-126/config.json\n",
      "Model weights saved in ./results/checkpoint-126/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-126/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-126/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-124] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-127\n",
      "Configuration saved in ./results/checkpoint-127/config.json\n",
      "Model weights saved in ./results/checkpoint-127/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-127/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-127/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-125] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-128\n",
      "Configuration saved in ./results/checkpoint-128/config.json\n",
      "Model weights saved in ./results/checkpoint-128/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-128/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-128/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-126] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-129\n",
      "Configuration saved in ./results/checkpoint-129/config.json\n",
      "Model weights saved in ./results/checkpoint-129/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-129/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-129/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-127] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-130\n",
      "Configuration saved in ./results/checkpoint-130/config.json\n",
      "Model weights saved in ./results/checkpoint-130/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-130/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-130/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-131\n",
      "Configuration saved in ./results/checkpoint-131/config.json\n",
      "Model weights saved in ./results/checkpoint-131/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-131/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-131/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-129] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-132\n",
      "Configuration saved in ./results/checkpoint-132/config.json\n",
      "Model weights saved in ./results/checkpoint-132/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-132/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-132/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-130] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-133\n",
      "Configuration saved in ./results/checkpoint-133/config.json\n",
      "Model weights saved in ./results/checkpoint-133/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-133/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-133/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-131] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-134\n",
      "Configuration saved in ./results/checkpoint-134/config.json\n",
      "Model weights saved in ./results/checkpoint-134/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-134/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-134/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-132] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-135\n",
      "Configuration saved in ./results/checkpoint-135/config.json\n",
      "Model weights saved in ./results/checkpoint-135/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-135/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-135/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-133] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-136\n",
      "Configuration saved in ./results/checkpoint-136/config.json\n",
      "Model weights saved in ./results/checkpoint-136/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-136/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-136/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-134] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-137\n",
      "Configuration saved in ./results/checkpoint-137/config.json\n",
      "Model weights saved in ./results/checkpoint-137/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-137/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-137/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-135] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-138\n",
      "Configuration saved in ./results/checkpoint-138/config.json\n",
      "Model weights saved in ./results/checkpoint-138/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-138/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-138/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-136] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-139\n",
      "Configuration saved in ./results/checkpoint-139/config.json\n",
      "Model weights saved in ./results/checkpoint-139/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-139/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-139/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-137] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-140\n",
      "Configuration saved in ./results/checkpoint-140/config.json\n",
      "Model weights saved in ./results/checkpoint-140/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-140/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-140/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-138] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-141\n",
      "Configuration saved in ./results/checkpoint-141/config.json\n",
      "Model weights saved in ./results/checkpoint-141/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-141/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-141/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-139] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-142\n",
      "Configuration saved in ./results/checkpoint-142/config.json\n",
      "Model weights saved in ./results/checkpoint-142/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-142/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-142/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-140] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-143\n",
      "Configuration saved in ./results/checkpoint-143/config.json\n",
      "Model weights saved in ./results/checkpoint-143/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-143/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-143/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-141] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-144\n",
      "Configuration saved in ./results/checkpoint-144/config.json\n",
      "Model weights saved in ./results/checkpoint-144/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-144/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-144/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-142] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-145\n",
      "Configuration saved in ./results/checkpoint-145/config.json\n",
      "Model weights saved in ./results/checkpoint-145/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-145/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-145/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-143] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-146\n",
      "Configuration saved in ./results/checkpoint-146/config.json\n",
      "Model weights saved in ./results/checkpoint-146/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-146/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-146/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-144] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-147\n",
      "Configuration saved in ./results/checkpoint-147/config.json\n",
      "Model weights saved in ./results/checkpoint-147/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-147/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-147/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-145] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-148\n",
      "Configuration saved in ./results/checkpoint-148/config.json\n",
      "Model weights saved in ./results/checkpoint-148/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-148/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-148/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-146] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-149\n",
      "Configuration saved in ./results/checkpoint-149/config.json\n",
      "Model weights saved in ./results/checkpoint-149/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-149/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-149/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-147] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 95\n",
      "  Batch size = 96\n",
      "Saving model checkpoint to ./results/checkpoint-150\n",
      "Configuration saved in ./results/checkpoint-150/config.json\n",
      "Model weights saved in ./results/checkpoint-150/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-150/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-150/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-148] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-150 (score: 0.5517480969429016).\n",
      "Deleting older checkpoint [results/checkpoint-149] due to args.save_total_limit\n",
      "Deleting older checkpoint [results/checkpoint-150] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=150, training_loss=0.8601989014943441, metrics={'train_runtime': 705.6321, 'train_samples_per_second': 20.195, 'train_steps_per_second': 0.213, 'total_flos': 3749433530112000.0, 'train_loss': 0.8601989014943441, 'epoch': 150.0})"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 24\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_prediction():\n",
    "    test_pred = trainer.predict(test_dataset)\n",
    "    labels = np.argmax(test_pred.predictions, axis=-1)\n",
    "    return labels\n",
    "pred = get_prediction()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy_score': 0.9583333333333334,\n 'precision_score': 0.9583333333333334,\n 'f1_score': 0.9583333333333334,\n 'recall_score': 0.9583333333333334}"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(y_test, pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in finetunebert/config.json\n",
      "Model weights saved in finetunebert/pytorch_model.bin\n",
      "tokenizer config file saved in finetunebert/tokenizer_config.json\n",
      "Special tokens file saved in finetunebert/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "('finetunebert/tokenizer_config.json',\n 'finetunebert/special_tokens_map.json',\n 'finetunebert/vocab.txt',\n 'finetunebert/added_tokens.json')"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"finetunebert\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
